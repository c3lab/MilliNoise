{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61892ad",
   "metadata": {},
   "source": [
    "# Simple Dataset Manipulation\n",
    "\n",
    "This notebook represents a simple way to get data from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f35667",
   "metadata": {},
   "source": [
    "Loading Libraries and Creating Function to load the dataset from the json file, as a Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b275c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits import mplot3d\n",
    "from scipy.spatial.transform import Rotation\n",
    "np.set_printoptions(threshold=np.infty)\n",
    "from utils_data_elab import VIC_OFF_X, VIC_OFF_Y, get_scenes, scene, obstacle, run, get_obs_info, get_scene_index\n",
    "\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 25\n",
    "mpl.rcParams['ytick.labelsize'] = 25\n",
    "# set axis label size to 25\n",
    "mpl.rcParams['font.size'] = 25\n",
    "\n",
    "path_to_json = \"./data/\"\n",
    "\n",
    "def list_dataset(path):\n",
    "    paths = []\n",
    "    for p in os.listdir(path):\n",
    "        if \"maps\" not in p and \\\n",
    "            \".csv\" not in p and \\\n",
    "            \"scene\" not in p: paths.append(p)\n",
    "    return paths\n",
    "\n",
    "def dict_dataset(path):\n",
    "    paths = {}\n",
    "    for p in sorted(os.listdir(path)):\n",
    "        if \"maps\" not in p and \\\n",
    "            \".csv\" not in p and \\\n",
    "            \"ignore\" not in p and \\\n",
    "            \"compress\" not in p and \\\n",
    "            \"scene\" not in p and \\\n",
    "            os.path.isdir(os.path.join(path, p)): \n",
    "            # print(p.replace('run_', ''))\n",
    "            x = str(int(p.replace('run_', '')))\n",
    "            paths[x] = \"run_\"+x\n",
    "    return paths\n",
    "\n",
    "def load_dataset(path_to_json, datasets, dataset_index, verbose=False):\n",
    "    if verbose: print(\" Loading: \", datasets[dataset_index])\n",
    "    data = open_json(path_to_json, datasets[dataset_index], verbose=verbose)\n",
    "    # obstacles = open_json(path_to_json,\"obstacles_scene\"+str(data[\"scene_ID\"])+\".json\")\n",
    "\n",
    "    # # Translate the obstacles in the inertial reference frame\n",
    "    # obstacles = np.array([np.subtract(obstacles['x'],3), np.subtract(obstacles['y'],2.7),obstacles['z']]).T\n",
    "\n",
    "    # Load Poses\n",
    "    poses = np.vstack(data[\"data_pose\"])\n",
    "\n",
    "    #Load mmWave Data (organised by timestamp)\n",
    "    print(\" data_mmwave shape:\", len(data[\"data_mmwave\"]))\n",
    "    mmw_readings = [np.atleast_2d(v) for v in data[\"data_mmwave\"]]\n",
    "    # mmw_readings_np = np.vstack(mmw_readings)\n",
    "    abs_mmw = apply_rototranslation(copy.deepcopy(mmw_readings), poses)\n",
    "\n",
    "    # Sometimes poses contain useless information, so we remove them\n",
    "    poses = np.subtract(poses[:len(mmw_readings),:], [VIC_OFF_X, VIC_OFF_Y, 0.])\n",
    "    return poses, abs_mmw, mmw_readings, data\n",
    "\n",
    "\n",
    "def open_json(path_to_run, run, verbose=True):\n",
    "    if verbose: print(\" Loading Dataset: \", path_to_run, run)\n",
    "    # json_path = path_to_run+run.replace('_', '')+\"/dataset_\"+run+\".json\"\n",
    "    json_path = path_to_run+run+\"/dataset_\"+run+\".json\"\n",
    "    json_path = os.path.join(os.getcwd(), json_path)\n",
    "    with open(json_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n Available Data: \")\n",
    "        for key in data.keys(): print(\"  - \", key)\n",
    "    return data\n",
    "\n",
    "\n",
    "def apply_rototranslation(mmw_readings, poses, offset_x=VIC_OFF_X, offset_y=VIC_OFF_Y):\n",
    "    assert len(poses) >= len(mmw_readings), \"Number of poses must be greater or equal than number of point clouds, but got {} and {}\".format(len(poses), len(mmw_readings))\n",
    "    \n",
    "    \n",
    "    # Compute Pointcloud Transformation\n",
    "    # to_global = np.eye(4)\n",
    "    abs_mmw = []\n",
    "    for pc_o, pose in zip(np.copy(mmw_readings), np.copy(poses)):\n",
    "        pc = pc_o[:, :3]\n",
    "\n",
    "        # # pc = np.hstack( [ pc, np.ones( (pc_o.shape[0], 1) ) ]).T\n",
    "        # # pose[:2] = np.subtract(pose[:2], [offset_x, offset_y])\n",
    "        # # R = Rotation.from_euler('XYZ', [0,0, pose[2]]).as_matrix()\n",
    "        # # to_global[:3, :3] = R\n",
    "        # # to_global[:3, 3] = [pose[0], pose[1], 0.1]\n",
    "        # # pc = np.matmul(to_global, pc).T\n",
    "\n",
    "        pc = Rotation.from_euler('XYZ', [0,0, pose[2]]).apply(pc)\n",
    "        pc = np.add(pc, [pose[0]-offset_x, pose[1]-offset_y, 0.1])\n",
    "        \n",
    "        pc_o[:, :3] = pc[:, :3]\n",
    "        abs_mmw.append(pc_o)\n",
    "\n",
    "    abs_mmw = np.vstack(abs_mmw)\n",
    "    return abs_mmw\n",
    "\n",
    "def plot_scene(point_cloud, \n",
    "        fake_points=[], \n",
    "        obstacles=[], \n",
    "        path=[], \n",
    "        colors=[], \n",
    "        pc_size=1,\n",
    "        fake_pc_size=1,\n",
    "        path_size=20, \n",
    "        min_xlim=-3.5, \n",
    "        max_xlim=3.5, \n",
    "        min_ylim=-3.5, \n",
    "        max_ylim=3.5,\n",
    "        dest_path=None):\n",
    "    # Plot Reconstructed Point Cloud\n",
    "    fig = plt.figure(figsize=(13, 13))\n",
    "    fig.set_tight_layout(True)\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_xlim([min_xlim, max_xlim])\n",
    "    ax.set_ylim([min_ylim, max_ylim])\n",
    "    ax.set_zlim([0, 1.5])\n",
    "    ax.view_init(elev=90, azim=180)\n",
    "\n",
    "    if np.shape(point_cloud)[1] > 3:\n",
    "        colors = colors if len(colors) > 0 else point_cloud[:, 3]\n",
    "    else: colors ='#689b64'\n",
    "    # ax.scatter(point_cloud[:, 0], point_cloud[:, 1], point_cloud[:, 2], s=pc_size, marker='.', c='#689b64')\n",
    "    ax.scatter(point_cloud[:, 0], point_cloud[:, 1], point_cloud[:, 2], s=pc_size, marker='.', c=colors)\n",
    "    \n",
    "    if len(fake_points) > 0:\n",
    "        ax.scatter(fake_points[:, 0], fake_points[:, 1], fake_points[:, 2], s=fake_pc_size, marker='.', c='#44546a')\n",
    "\n",
    "    # Plot Obstacles\n",
    "    if len(obstacles) > 0:\n",
    "        ax.scatter(obstacles[:, 0], obstacles[:, 1], obstacles[:, 2], s=1, marker='.', c='r')\n",
    "\n",
    "    # Plot Trajectory\n",
    "    if len(path) > 0:\n",
    "        ax.scatter(path[0, 0], path[0,1], 0.1, s=path_size+5, marker='o', c='green')\n",
    "        ax.scatter(path[1:-1, 0], path[1:-1,1], np.full(len(path)-2, 0.1), s=path_size, marker='.', c='green')\n",
    "        ax.scatter(path[-1, 0], path[-1, 1], 0.1, s=path_size+5, marker='x', c='green')\n",
    "\n",
    "    if not dest_path:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(dest_path)\n",
    "\n",
    "def plot_2dscene(point_cloud, \n",
    "        fake_points=[], \n",
    "        obstacles=[], \n",
    "        path=[], \n",
    "        colors=[], \n",
    "        pc_size=1,\n",
    "        fake_pc_size=1,\n",
    "        path_size=20, \n",
    "        min_xlim=-3.5, \n",
    "        max_xlim=3.5, \n",
    "        min_ylim=-3.5, \n",
    "        max_ylim=3.5,\n",
    "        dest_path=None):\n",
    "    # Plot Reconstructed Point Cloud\n",
    "    fig = plt.figure(figsize=(13, 13))\n",
    "    fig.set_tight_layout(True)\n",
    "    ax = fig.add_subplot()\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.grid(False)\n",
    "    # ax.set_zlabel('Z')\n",
    "    ax.set_xlim([min_xlim, max_xlim])\n",
    "    ax.set_ylim([min_ylim, max_ylim])\n",
    "    # ax.set_zlim([0, 1.5])\n",
    "    # ax.view_init(elev=90, azim=180)\n",
    "\n",
    "    if np.shape(point_cloud)[1] > 3:\n",
    "        colors = colors if len(colors) > 0 else point_cloud[:, 3]\n",
    "    else: colors ='#689b64'\n",
    "    # ax.scatter(point_cloud[:, 0], point_cloud[:, 1], point_cloud[:, 2], s=pc_size, marker='.', c='#689b64')\n",
    "    # ax.scatter(point_cloud[:, 0], point_cloud[:, 1], s=pc_size, marker='.', c=colors)\n",
    "    ax.scatter(point_cloud[:, 0], point_cloud[:, 1], s=pc_size, marker='.', c='#D3BD0F')\n",
    "    \n",
    "    if len(fake_points) > 0:\n",
    "        ax.scatter(fake_points[:, 0], fake_points[:, 1], s=fake_pc_size, marker='.', c='#44546a')\n",
    "\n",
    "    # Plot Obstacles\n",
    "    if len(obstacles) > 0:\n",
    "        ax.scatter(obstacles[:, 0], obstacles[:, 1], s=1, marker='.', c='r')\n",
    "\n",
    "    # Plot Trajectory\n",
    "    if len(path) > 0:\n",
    "        ax.scatter(path[0, 0], path[0,1], s=path_size+5, marker='o', c='green')\n",
    "        ax.scatter(path[1:-1, 0], path[1:-1,1], s=path_size, marker='.', c='green')\n",
    "        ax.scatter(path[-1, 0], path[-1, 1], s=path_size+5, marker='x', c='green')\n",
    "\n",
    "    if not dest_path:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(dest_path)\n",
    "    \n",
    "def arena_filter(pc):\n",
    "    return list(np.where(\n",
    "            ((pc[:, 0] > -3.81) & (pc[:, 1] > -3.38) & (pc[:, 0] < 3.95) & (pc[:, 1] < 3.2) & (pc[:, 2] >= 0)) & \\\n",
    "            ((pc[:, 0] < -3.61) | (pc[:, 1] < -3.18) | (pc[:, 0] > 3.15) | (pc[:, 1] > 3.0) & (pc[:, 2] < 4))\n",
    "        )[0])\n",
    "\n",
    "\n",
    "def update_refer_frame(mmw_readings, poses, offset_x=VIC_OFF_X, offset_y=VIC_OFF_Y):\n",
    "    assert len(poses) >= len(mmw_readings), \\\n",
    "        \"Number of poses must be greater or equal than number of point clouds, but got {} and {}\".format(len(poses), len(mmw_readings))\n",
    "\n",
    "    # Compute Pointcloud Transformation\n",
    "    abs_mmw = []\n",
    "    for pc_o, pose in zip(np.copy(mmw_readings), np.copy(poses)):\n",
    "        pc = pc_o[:, :3]\n",
    "\n",
    "        pc = np.add(pc, [(pose[0]-offset_x), (pose[1]-offset_y), 0.1])\n",
    "        pc = np.matmul(pc, Rotation.from_euler('XYZ', [0., 0., pose[2]]).as_matrix())\n",
    "\n",
    "        # pc_o[:, :3] = pc[:, :3]\n",
    "        abs_mmw.append(pc)\n",
    "\n",
    "    abs_mmw = np.vstack(abs_mmw)\n",
    "    return abs_mmw\n",
    "\n",
    "def quad_dist2(abs_mmw, box):\n",
    "    t_ = np.copy(abs_mmw[:, :3])\n",
    "    angles = np.arctan2(t_[:, 1], t_[:, 0])\n",
    "    box_angle1 = np.arctan2(box[2], box[0])\n",
    "    box_angle2 = np.arctan2(box[2], box[1])\n",
    "    box_angle3 = np.arctan2(box[3], box[1])\n",
    "    box_angle4 = np.arctan2(box[3], box[0])\n",
    "    print(box_angle1*180/np.pi, box_angle2*180/np.pi, box_angle3*180/np.pi, box_angle4*180/np.pi)\n",
    "\n",
    "    q1 = np.logical_and(angles >= box_angle4, angles < box_angle1)\n",
    "    q2 = np.logical_and(angles >= box_angle1, angles < box_angle2)\n",
    "    q3 = np.logical_or (angles >= box_angle2, angles < box_angle3)\n",
    "    q4 = np.logical_and(angles >= box_angle3, angles < box_angle4)\n",
    "    print(np.sum(q1), np.sum(q2), np.sum(q3), np.sum(q4), \" = \", np.sum(q1)+np.sum(q2)+np.sum(q3)+np.sum(q4))\n",
    "\n",
    "    dq1 = np.multiply((box[0] < t_[:, 0]) & q1, np.abs(box[0] - t_[:, 0]))   # Distance from Front Wall\n",
    "    dq2 = np.multiply((box[1] > t_[:, 0]) & q3, np.abs(box[1] - t_[:, 0]))   # Distance from Back Wall\n",
    "    dq3 = np.multiply((box[2] < t_[:, 1]) & q2, np.abs(box[2] - t_[:, 1]))   # Distance from Left Wall\n",
    "    dq4 = np.multiply((box[3] > t_[:, 1]) & q4, np.abs(box[3] - t_[:, 1]))   # Distance from Right Wall\n",
    "\n",
    "    dq = np.vstack([dq1, dq2, dq3, dq4]).T\n",
    "    return np.sum(dq, axis=1)\n",
    "\n",
    "def obstacles_filter(abs_mmw, pos, dims, tops, offset_x=VIC_OFF_X, offset_y=VIC_OFF_Y, verbose=False):\n",
    "\n",
    "    tmp1 = np.array([False]*abs_mmw.shape[0])\n",
    "    mmw_t = [abs_mmw[i:i+200] for i in range(0, abs_mmw.shape[0], 200)]\n",
    "    dists = []\n",
    "\n",
    "    i = 0\n",
    "    for i in range(len(pos)):\n",
    "        yaw_off = np.pi/2 if \"vicon/Obstacle\" in tops[i] and not(\"vicon/ObstacleMonitor\" in tops[i]) else 0\n",
    "        # print(\" obs: \", tops[i], \"pos(t)\", pos[i], \" IS TRUE: \", (\"vicon/Obstacle\" in tops[i] and not(\"vicon/ObstacleMonitor\" in tops[i])), \" offset: \", yaw_off)\n",
    "        t = [[ \n",
    "            -(pos[i][0] - VIC_OFF_X), -(pos[i][1] - VIC_OFF_Y), (pos[i][2] + yaw_off)\n",
    "        ]]*(len(mmw_t))\n",
    "        tmp_ = np.array(update_refer_frame(copy.deepcopy(mmw_t), copy.deepcopy(t), offset_x=0, offset_y=0))\n",
    "        if verbose:\n",
    "            print(\" obs: \", tops[i], \"pos(t)\", t[0], \" dims: \", dims[i])\n",
    "            print(\" pos: \", pos[i])\n",
    "        tmp2 = np.where((\n",
    "            (\n",
    "                (tmp_[:, 0] > -dims[i][0]/2) & \\\n",
    "                (tmp_[:, 0] < dims[i][0]/2) \\\n",
    "            ) & \\\n",
    "            (\n",
    "                (tmp_[:, 1] > -dims[i][1]/2) & \\\n",
    "                (tmp_[:, 1] < dims[i][1]/2) \\\n",
    "            )\n",
    "        ))[0]\n",
    "        tmp1[tmp2] = True\n",
    "        \n",
    "        x_ = quad_dist2(tmp_, box=[dims[i][0]/2, -dims[i][0]/2, dims[i][1]/2, -dims[i][1]/2])\n",
    "        # x_[x_ == 0.] = 15\n",
    "        # plot_scene(abs_mmw, colors=x_)\n",
    "        # break\n",
    "        dists.append(x_)\n",
    "    dists = np.vstack(dists).T\n",
    "    dists = dists.min(axis=1)\n",
    "    return tmp1, dists\n",
    "\n",
    "def inside_walls(abs_mmw):\n",
    "    t_ = np.copy(abs_mmw[:, :3])\n",
    "    p2bw_dist = np.multiply((0. > -3.61 - t_[:, 0]), np.abs(-3.61 - t_[:, 0]))   # Distance from Back Wall\n",
    "    p2fw_dist = np.multiply((0. <  3.15 - t_[:, 0]), np.abs( 3.15 - t_[:, 0]))   # Distance from Front Wall\n",
    "    p2lw_dist = np.multiply((0. <  3.00 - t_[:, 1]), np.abs( 3.00 - t_[:, 1]))   # Distance from Left Wall\n",
    "    p2rw_dist = np.multiply((0. > -3.18 - t_[:, 1]), np.abs(-3.18 - t_[:, 1]))   # Distance from Right Wall\n",
    "    p2ws = np.vstack([p2bw_dist, p2fw_dist, p2lw_dist, p2rw_dist]).T\n",
    "    # print(p2ws.shape)\n",
    "    return p2ws.min(axis=1)\n",
    "\n",
    "def keep_borders(pc, dims, border):\n",
    "    return list(np.where(\n",
    "                ((pc[:, 0] > dims[0]/2-border) & (pc[:, 1] > dims[1]/2-border) |\\\n",
    "                 (pc[:, 0] < -dims[0]/2+border) & (pc[:, 1] < -dims[1]/2+border)) | \\\n",
    "                ((pc[:, 0] < -dims[0]/2+border) | (pc[:, 1] < -dims[1]/2+border) |\\\n",
    "                 (pc[:, 0] > dims[0]/2-border) | (pc[:, 1] > dims[1]/2-border))\n",
    "        )[0])\n",
    "\n",
    "# Generate random obstacles\n",
    "def generate_abs_bounding_obstacle(i_pos, i_dims, n_points, border=0.03):\n",
    "    obstacles_x = np.random.uniform(-i_dims[0]/2, i_dims[0]/2, n_points)\n",
    "    obstacles_y = np.random.uniform(-i_dims[1]/2, i_dims[1]/2, n_points)\n",
    "    obstacles_z = np.ones_like(obstacles_x)\n",
    "    obstacles = np.column_stack([obstacles_x, obstacles_y, obstacles_z])\n",
    "    obstacles = obstacles[keep_borders(obstacles, i_dims, border)]\n",
    "    obstacles = obstacles.reshape(obstacles.shape[0], 1, 3)\n",
    "    obs_poses = np.array([i_pos]*n_points)\n",
    "    abs_obstacles = apply_rototranslation(obstacles, obs_poses)\n",
    "    return abs_obstacles\n",
    "\n",
    "def generate_abs_bounding_obstacles(pos, dims, tops, n_points, border=0.3):\n",
    "    abs_obstacles = []\n",
    "    for i in range(len(pos)):\n",
    "        if \"vicon/Obstacle\" in tops[i] and not(\"vicon/ObstacleMonitor\" in tops[i]):\n",
    "            pos[i][2] += np.pi/2\n",
    "        print(\" Generating obstacle \", i, \" at \", pos[i], \"with topic \", tops[i])\n",
    "        abs_obstacles.append(generate_abs_bounding_obstacle(pos[i], dims[i], n_points, border))\n",
    "\n",
    "    abs_obstacles = np.vstack(abs_obstacles)\n",
    "    return abs_obstacles\n",
    "    \n",
    "\n",
    "def get_point_labels(datasets, dataset_index, path_to_json, scene_fn=\"./data/data_scene\"):\n",
    "    _, abs_mmw, _, _ = load_dataset(datasets, dataset_index)\n",
    "    scenes = get_scenes(scene_fn)\n",
    "    scene_index = get_scene_index(datasets[dataset_index], base_path=path_to_json)\n",
    "    pos, dims, tops = get_obs_info(scenes[scene_index])\n",
    "\n",
    "    print([x.topic for x in scenes[scene_index].obs])\n",
    "\n",
    "    print(f\" Run {datasets[dataset_index]} - Scene {scene_index} - # Obstacles: {len(pos)} \")\n",
    "\n",
    "    surv = arena_filter(abs_mmw)\n",
    "    # surv.append(obstacles_filter(abs_mmw, obs_range_x, obs_range_y))\n",
    "    surv = np.hstack(surv)\n",
    "\n",
    "    # abs_filt = abs_mmw[surv]\n",
    "    # plot_scene(abs_mmw, path=poses)\n",
    "\n",
    "\n",
    "    labels = np.array([False]*abs_mmw.shape[0])\n",
    "    labels[surv] = True\n",
    "    not_labels = np.logical_not(labels)\n",
    "    # res = obstacles_filter2(abs_mmw, pos, dims, tops, verbose=True)\n",
    "    res, dists = obstacles_filter(abs_mmw, pos, dims, tops, verbose=True)\n",
    "\n",
    "    labels[res] = True\n",
    "    not_labels = np.logical_not(labels)\n",
    "    true_obs = np.sum(labels)/len(labels)\n",
    "    false_obs = np.sum(np.logical_not(labels))/len(labels)\n",
    "    # print first 3 digits of true_obs and false_obs\n",
    "    print(\" True Obstacles:\", round(true_obs*100, 2), \"\\n False Obstacles:\", round(false_obs*100, 2))\n",
    "    return labels, not_labels, pos, dims, tops\n",
    "\n",
    "\n",
    "def compute_distv1(abs_mmw, pos, dims, tops, verbose=False):\n",
    "    p2ws = inside_walls(abs_mmw)\n",
    "    dq = quad_dist2(abs_mmw, box = [3.95, -3.81, 3.20, -3.38])\n",
    "    wall_d = np.sum(np.vstack([dq, p2ws]).T, axis=1)\n",
    "    tmp1, dists = obstacles_filter(abs_mmw, pos, dims, tops, verbose=verbose)\n",
    "    dists = np.vstack([dists, wall_d]).T.min(axis=1)\n",
    "    # dists[dists == 0.] = 5\n",
    "    return dists\n",
    "\n",
    "def stack_labels_dists(mmw_readings, labels, dists):\n",
    "    labelled_mmw = []\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(len(mmw_readings)):\n",
    "        current_size = len(mmw_readings[i])\n",
    "        labelled_mmw.append(np.column_stack((mmw_readings[i], labels[counter:counter+current_size], dists[counter:counter+current_size])).tolist())\n",
    "        counter += current_size\n",
    "    return labelled_mmw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02858f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data_mmwave shape: 1000\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Number of poses must be greater or equal than number of point clouds, but got 232 and 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m scenes \u001b[38;5;241m=\u001b[39m get_scenes(path_to_json\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data_scene\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_index \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mlist\u001b[39m(datasets\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m34\u001b[39m]]:\n\u001b[0;32m----> 6\u001b[0m     poses, abs_mmw, mmw_readings, data \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     pos, dims, tops \u001b[38;5;241m=\u001b[39m get_obs_info(scenes[data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscene_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m      8\u001b[0m     abs_obstacles \u001b[38;5;241m=\u001b[39m generate_abs_bounding_obstacles(pos, dims, tops, n_points, border)\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path_to_json, datasets, dataset_index, verbose)\u001b[0m\n\u001b[1;32m     56\u001b[0m mmw_readings \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39matleast_2d(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_mmwave\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# mmw_readings_np = np.vstack(mmw_readings)\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m abs_mmw \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rototranslation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmmw_readings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Sometimes poses contain useless information, so we remove them\u001b[39;00m\n\u001b[1;32m     61\u001b[0m poses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msubtract(poses[:\u001b[38;5;28mlen\u001b[39m(mmw_readings),:], [VIC_OFF_X, VIC_OFF_Y, \u001b[38;5;241m0.\u001b[39m])\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mapply_rototranslation\u001b[0;34m(mmw_readings, poses, offset_x, offset_y)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_rototranslation\u001b[39m(mmw_readings, poses, offset_x\u001b[38;5;241m=\u001b[39mVIC_OFF_X, offset_y\u001b[38;5;241m=\u001b[39mVIC_OFF_Y):\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(poses) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(mmw_readings), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of poses must be greater or equal than number of point clouds, but got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(poses), \u001b[38;5;28mlen\u001b[39m(mmw_readings))\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# Compute Pointcloud Transformation\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# to_global = np.eye(4)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     abs_mmw \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAssertionError\u001b[0m: Number of poses must be greater or equal than number of point clouds, but got 232 and 1000"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "n_points = 50000\n",
    "border = 0.025\n",
    "datasets = dict_dataset(path_to_json)\n",
    "scenes = get_scenes(path_to_json+\"/data_scene\")\n",
    "for dataset_index in [list(datasets.keys())[34]]:\n",
    "    poses, abs_mmw, mmw_readings, data = load_dataset(path_to_json, datasets, dataset_index)\n",
    "    pos, dims, tops = get_obs_info(scenes[data[\"scene_ID\"]])\n",
    "    abs_obstacles = generate_abs_bounding_obstacles(pos, dims, tops, n_points, border)\n",
    "    labels, not_labels, pos, dims, tops = get_point_labels(datasets, dataset_index, path_to_json)\n",
    "    dists = compute_distv1(abs_mmw, pos, dims, tops)\n",
    "    stacked_mmw = stack_labels_dists(mmw_readings, labels, dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7462fa7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['scene_ID', 'init_pose', 'run_total_time', 'timestamp', 'data_laser', 'data_imu', 'data_pose', 'data_camera_image_path', 'data_mmwave', 'data_camera_depth_path', 'missing_mmWave_idx'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot_2dscene(abs_mmw, obstacles=abs_obstacles, colors=labels)\n",
    "plot_2dscene(abs_mmw[labels], fake_points=abs_mmw[not_labels], obstacles=abs_obstacles, path=poses, path_size=35, dest_path='figures/scene9_run81example.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_mmw(mmw_readings, labels):\n",
    "    labelled_mmw = []\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(len(mmw_readings)):\n",
    "        current_size = len(mmw_readings[i])\n",
    "        labelled_mmw.append(np.column_stack((mmw_readings[i], labels[counter:counter+current_size])).tolist())\n",
    "        counter += current_size\n",
    "    return labelled_mmw\n",
    "\n",
    "labelled_mmw = label_mmw(mmw_readings, labels)\n",
    "\n",
    "plot_2dscene(abs_mmw, obstacles=abs_obstacles, colors=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
